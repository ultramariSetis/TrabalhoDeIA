{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Projeto: Segmentação de Clientes com Autoencoder + KMeans\n",
        "Base: Mall Customers (Mall_Customers.csv)\n",
        "Como usar:\n",
        " - Coloque 'Mall_Customers.csv' na mesma pasta ou carregue no Colab.\n",
        " - Instale dependências: pip install pandas numpy scikit-learn matplotlib seaborn tensorflow\n",
        "\"\"\"\n",
        "\n",
        "import os\n",
        "import random\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.metrics import silhouette_score\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models, callbacks, optimizers\n",
        "\n",
        "# --- Reprodutibilidade ---\n",
        "SEED = 42\n",
        "np.random.seed(SEED)\n",
        "tf.random.set_seed(SEED)\n",
        "random.seed(SEED)\n",
        "os.environ['PYTHONHASHSEED'] = str(SEED)\n",
        "\n",
        "# --- Configurações (ajuste conforme necessário) ---\n",
        "CSV_PATH = \"Mall_Customers.csv\"   # caminho para o CSV\n",
        "FEATURES = [\"Age\", \"Annual Income (k$)\", \"Spending Score (1-100)\"]\n",
        "USE_GENDER = True                 # incluir Gender como feature binária?\n",
        "LATENT_DIM = 3                    # dimensão do bottleneck do autoencoder\n",
        "BATCH_SIZE = 16\n",
        "EPOCHS = 200\n",
        "VALIDATION_SPLIT = 0.2\n",
        "N_CLUSTERS = 5                    # número inicial de clusters KMeans\n",
        "PLOT_SAVE_DIR = \"outputs\"\n",
        "\n",
        "os.makedirs(PLOT_SAVE_DIR, exist_ok=True)\n",
        "\n",
        "# --- 1. Carregar dados ---\n",
        "if not os.path.exists(CSV_PATH):\n",
        "    raise FileNotFoundError(f\"Arquivo '{CSV_PATH}' não encontrado. Coloque o CSV no diretório ou ajuste CSV_PATH.\")\n",
        "df = pd.read_csv(CSV_PATH)\n",
        "\n",
        "# Mostra as primeiras linhas\n",
        "print(\"Preview dos dados:\")\n",
        "print(df.head())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YNhW6up3_Dv4",
        "outputId": "26a8ef6a-ba5c-48e7-89f6-0126efc422ef"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Preview dos dados:\n",
            "   CustomerID   Genre  Age  Annual Income (k$)  Spending Score (1-100)\n",
            "0           1    Male   19                  15                      39\n",
            "1           2    Male   21                  15                      81\n",
            "2           3  Female   20                  16                       6\n",
            "3           4  Female   23                  16                      77\n",
            "4           5  Female   31                  17                      40\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 2. Pré-processamento ---\n",
        "data = df.copy()\n",
        "le = LabelEncoder()\n",
        "\n",
        "# Opcional: codificar gênero\n",
        "if USE_GENDER and 'Genre' in data.columns:\n",
        "    data['Gender_bin'] = le.fit_transform(data['Genre'])\n",
        "    feature_cols = FEATURES + ['Gender_bin']\n",
        "else:\n",
        "    feature_cols = FEATURES\n",
        "\n",
        "# Seleciona apenas as features desejadas\n",
        "X = data[feature_cols].copy()\n",
        "# Renomeia colunas problemáticas\n",
        "X.columns = [c.replace(\" \", \"_\").replace(\"(\", \"\").replace(\")\", \"\").replace(\"–\",\"-\") for c in X.columns]\n",
        "\n",
        "# Verificação de NA\n",
        "if X.isnull().any().any():\n",
        "    print(\"Existem NAs — preenchendo com mediana.\")\n",
        "    X = X.fillna(X.median())\n",
        "\n",
        "# Escalonamento\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "print(\"\\nFeatures usadas:\", feature_cols)\n",
        "print(\"Shape do dataset (após escalonamento):\", X_scaled.shape)\n"
      ],
      "metadata": {
        "id": "mVonwb4d_ITe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 3. Construção do Autoencoder ---\n",
        "input_dim = X_scaled.shape[1]\n",
        "encoding_dim = LATENT_DIM\n",
        "\n",
        "# Encoder\n",
        "input_layer = layers.Input(shape=(input_dim,))\n",
        "x = layers.Dense(64, activation='relu')(input_layer)\n",
        "x = layers.Dense(32, activation='relu')(x)\n",
        "encoded = layers.Dense(encoding_dim, activation='linear', name='bottleneck')(x)\n",
        "\n",
        "# Decoder\n",
        "x = layers.Dense(32, activation='relu')(encoded)\n",
        "x = layers.Dense(64, activation='relu')(x)\n",
        "decoded = layers.Dense(input_dim, activation='linear')(x)\n",
        "\n",
        "autoencoder = models.Model(inputs=input_layer, outputs=decoded, name='autoencoder')\n",
        "encoder = models.Model(inputs=input_layer, outputs=encoded, name='encoder')\n",
        "\n",
        "autoencoder.compile(optimizer=optimizers.Adam(learning_rate=1e-3), loss='mse')\n",
        "\n",
        "autoencoder.summary()"
      ],
      "metadata": {
        "id": "FWZ6_JPl_W8-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 4. Treino do Autoencoder ---\n",
        "es = callbacks.EarlyStopping(monitor='val_loss', patience=15, restore_best_weights=True, verbose=1)\n",
        "\n",
        "history = autoencoder.fit(\n",
        "    X_scaled, X_scaled,\n",
        "    epochs=EPOCHS,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    validation_split=VALIDATION_SPLIT,\n",
        "    callbacks=[es],\n",
        "    verbose=2\n",
        ")\n",
        "\n",
        "# salva histórico de treino (plot)\n",
        "plt.figure(figsize=(8,4))\n",
        "plt.plot(history.history['loss'], label='train_loss')\n",
        "plt.plot(history.history['val_loss'], label='val_loss')\n",
        "plt.title('Autoencoder Loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.ylabel('MSE Loss')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.tight_layout()\n",
        "plt.savefig(os.path.join(PLOT_SAVE_DIR, 'autoencoder_loss.png'))\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "k9uebJR2_amd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 5. Extração do Espaço Latente (Embeddings) ---\n",
        "embeddings = encoder.predict(X_scaled)\n",
        "print(\"Shape do espaço latente:\", embeddings.shape)\n",
        "\n",
        "# Se LATENT_DIM > 2, podemos reduzir para 2D apenas para visualização (PCA)\n",
        "if embeddings.shape[1] > 2:\n",
        "    pca_vis = PCA(n_components=2, random_state=SEED)\n",
        "    emb_2d = pca_vis.fit_transform(embeddings)\n",
        "else:\n",
        "    emb_2d = embeddings"
      ],
      "metadata": {
        "id": "K1im8s6Q_fXl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 6. Clusterização com KMeans no espaço latente ---\n",
        "kmeans = KMeans(n_clusters=N_CLUSTERS, random_state=SEED, n_init=20)\n",
        "clusters = kmeans.fit_predict(embeddings)\n",
        "\n",
        "# Métrica de qualidade\n",
        "sil = silhouette_score(embeddings, clusters)\n",
        "print(f\"Silhouette Score (latent space) para k={N_CLUSTERS}: {sil:.4f}\")\n",
        "\n",
        "# Anexa resultados ao dataframe original\n",
        "data['cluster'] = clusters\n",
        "data['embed_1'] = emb_2d[:,0]\n",
        "data['embed_2'] = emb_2d[:,1]\n"
      ],
      "metadata": {
        "id": "Io5oVivB_idl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 7. Visualizações ---\n",
        "plt.figure(figsize=(8,6))\n",
        "sns.scatterplot(x='embed_1', y='embed_2', hue='cluster', palette='tab10', data=data, s=60)\n",
        "plt.title(f'Clusters no espaço latente (k={N_CLUSTERS})')\n",
        "plt.legend(title='cluster', bbox_to_anchor=(1.05,1), loc='upper left')\n",
        "plt.tight_layout()\n",
        "plt.savefig(os.path.join(PLOT_SAVE_DIR, 'clusters_latent_space.png'))\n",
        "plt.show()\n",
        "\n",
        "# Plot das features reais com clusters\n",
        "pair_cols = X.columns.tolist()\n",
        "if len(pair_cols) >= 2:\n",
        "    plt.figure(figsize=(8,6))\n",
        "    sns.scatterplot(x=pair_cols[0], y=pair_cols[1], hue='cluster', data=pd.concat([X.reset_index(drop=True), data['cluster']], axis=1), s=60)\n",
        "    plt.title(f'Clusters em {pair_cols[0]} x {pair_cols[1]}')\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(os.path.join(PLOT_SAVE_DIR, 'clusters_feature_space.png'))\n",
        "    plt.show()\n",
        "\n",
        "# Estatísticas por cluster\n",
        "cluster_summary = data.groupby('cluster')[feature_cols].agg(['count', 'mean', 'median', 'std'])\n",
        "print(\"\\nResumo por cluster (algumas estatísticas):\")\n",
        "print(cluster_summary)\n",
        "\n",
        "# Avaliar cada cluster por estatística\n",
        "summary = df.groupby('cluster')[['Age', 'Annual Income (k$)', 'Spending Score (1-100)']].mean()\n",
        "print(summary)\n",
        "\n",
        "# Salva resultados\n",
        "data.to_csv(os.path.join(PLOT_SAVE_DIR, 'mall_customers_with_clusters.csv'), index=False)\n",
        "encoder.save(os.path.join(PLOT_SAVE_DIR, 'encoder_model.h5'))\n",
        "autoencoder.save(os.path.join(PLOT_SAVE_DIR, 'autoencoder_model.h5'))\n",
        "\n",
        "print(f\"\\nResultados e modelos salvos em: {PLOT_SAVE_DIR}\")"
      ],
      "metadata": {
        "id": "QlkCL39i_qCl"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}